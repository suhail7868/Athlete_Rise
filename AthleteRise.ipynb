{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFZAVFiJy9F1",
        "outputId": "bc944ae3-8f41-45dd-9a23-3c521a0e1f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe==0.10.* in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.8.11)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.*) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.*) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.*) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.*) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.*) (1.16.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.*) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.*) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.*) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.*) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.*) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.*) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.*) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.*) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.*) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.*) (1.17.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe==0.10.* opencv-python yt-dlp\n",
        "!apt-get install ffmpeg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Setup"
      ],
      "metadata": {
        "id": "ucQuUO7-zcbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import math, json, os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Optional\n",
        "import yt_dlp"
      ],
      "metadata": {
        "id": "HoFq9U__ze60"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONFIG"
      ],
      "metadata": {
        "id": "-daWG54xzmTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_VIDEO = \"https://youtube.com/shorts/vSX3IRxGnNY\"\n",
        "OUTPUT_DIR = Path(\"/content/output\")\n",
        "CHECK_IMG_PATH = \"/content/sample_data/check.png\"\n",
        "CROSS_IMG_PATH = \"/content/sample_data/cross.png\"\n",
        "TARGET_WIDTH = 960\n",
        "TARGET_FPS = 30\n",
        "\n",
        "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)"
      ],
      "metadata": {
        "id": "6CMN4g_xzoca"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load PNG icons"
      ],
      "metadata": {
        "id": "1_3I8YOkz70c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_img = cv2.imread(CHECK_IMG_PATH, cv2.IMREAD_UNCHANGED)\n",
        "cross_img = cv2.imread(CROSS_IMG_PATH, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "def overlay_png(bg, fg, x, y, scale=1.0):\n",
        "    \"\"\"Overlay transparent PNG onto background.\"\"\"\n",
        "    if fg is None:\n",
        "        return\n",
        "    h, w = int(fg.shape[0] * scale), int(fg.shape[1] * scale)\n",
        "    fg = cv2.resize(fg, (w, h))\n",
        "    if fg.shape[2] != 4:\n",
        "        return\n",
        "    y1, y2 = max(0, y), min(bg.shape[0], y + h)\n",
        "    x1, x2 = max(0, x), min(bg.shape[1], x + w)\n",
        "    if y1 >= y2 or x1 >= x2:\n",
        "        return\n",
        "    fg_crop = fg[0:y2-y1, 0:x2-x1]\n",
        "    alpha = fg_crop[:, :, 3] / 255.0\n",
        "    for c in range(3):\n",
        "        bg[y1:y2, x1:x2, c] = (\n",
        "            alpha * fg_crop[:, :, c] + (1 - alpha) * bg[y1:y2, x1:x2, c]\n",
        "        )"
      ],
      "metadata": {
        "id": "vlhzjNkI0DBB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thresholds & Stats"
      ],
      "metadata": {
        "id": "0-qud4Qn0TZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Thresholds:\n",
        "    elbow_min: float = 80.0\n",
        "    elbow_max: float = 150.0\n",
        "    spine_lean_max: float = 20.0\n",
        "    head_knee_max_px_ratio: float = 0.06\n",
        "    foot_angle_target: float = 25.0\n",
        "    foot_angle_tol: float = 20.0\n",
        "\n",
        "@dataclass\n",
        "class RunningStats:\n",
        "    elbow_angles: list = field(default_factory=list)\n",
        "    spine_leans: list = field(default_factory=list)\n",
        "    head_knee_dxs: list = field(default_factory=list)\n",
        "    foot_angles: list = field(default_factory=list)\n"
      ],
      "metadata": {
        "id": "E9tmBX5D0Y2x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mediapipe setup"
      ],
      "metadata": {
        "id": "6QpDRxwF0h7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose"
      ],
      "metadata": {
        "id": "VmDHtXen0jwW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geometry helpers"
      ],
      "metadata": {
        "id": "_Xg6Yv1z0qDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _angle_deg(a, b, c):\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "    if np.linalg.norm(ba) == 0 or np.linalg.norm(bc) == 0:\n",
        "        return None\n",
        "    cosang = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "    cosang = max(min(cosang, 1.0), -1.0)\n",
        "    return math.degrees(math.acos(cosang))\n",
        "\n",
        "def _angle_vs_vertical(p1, p2):\n",
        "    v = p2 - p1\n",
        "    if np.linalg.norm(v) == 0:\n",
        "        return None\n",
        "    dot = v[0] * 0 + v[1] * (-1)\n",
        "    cosang = dot / (np.linalg.norm(v) * 1.0)\n",
        "    cosang = max(min(cosang, 1.0), -1.0)\n",
        "    return abs(math.degrees(math.acos(cosang)))\n",
        "\n",
        "def _line_angle_vs_x_axis(p1, p2):\n",
        "    v = p2 - p1\n",
        "    if np.linalg.norm(v) == 0:\n",
        "        return None\n",
        "    ang = math.degrees(math.atan2(v[1], v[0]))\n",
        "    return abs(ang)\n"
      ],
      "metadata": {
        "id": "VzvQmVAC0xyn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Landmark helpers"
      ],
      "metadata": {
        "id": "_VGc74vI028e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def landmarks_to_xy(frame_w, frame_h, pose_landmarks):\n",
        "    id2pt = {idx: (lm.x * frame_w, lm.y * frame_h)\n",
        "             for idx, lm in enumerate(pose_landmarks.landmark)}\n",
        "    P = mp_pose.PoseLandmark\n",
        "    out = {}\n",
        "    def put(name, landmark):\n",
        "        out[name] = id2pt[int(landmark)]\n",
        "    for name in [\"NOSE\", \"LEFT_SHOULDER\", \"RIGHT_SHOULDER\",\n",
        "                 \"LEFT_ELBOW\", \"RIGHT_ELBOW\", \"LEFT_WRIST\", \"RIGHT_WRIST\",\n",
        "                 \"LEFT_HIP\", \"RIGHT_HIP\", \"LEFT_KNEE\", \"RIGHT_KNEE\",\n",
        "                 \"LEFT_ANKLE\", \"RIGHT_ANKLE\", \"LEFT_FOOT_INDEX\", \"RIGHT_FOOT_INDEX\"]:\n",
        "        put(name, getattr(P, name))\n",
        "    if \"LEFT_HIP\" in out and \"RIGHT_HIP\" in out:\n",
        "        out[\"MID_HIP\"] = tuple(((np.array(out[\"LEFT_HIP\"]) + np.array(out[\"RIGHT_HIP\"])) / 2.0).tolist())\n",
        "    if \"LEFT_SHOULDER\" in out and \"RIGHT_SHOULDER\" in out:\n",
        "        out[\"MID_SHOULDER\"] = tuple(((np.array(out[\"LEFT_SHOULDER\"]) + np.array(out[\"RIGHT_SHOULDER\"])) / 2.0).tolist())\n",
        "    return out\n",
        "def compute_metrics(landmarks, frame_w):\n",
        "    metrics = {}\n",
        "    # Front elbow angle\n",
        "    angles = []\n",
        "    for side in (\"LEFT\", \"RIGHT\"):\n",
        "        shoulder = landmarks.get(f\"{side}_SHOULDER\")\n",
        "        elbow = landmarks.get(f\"{side}_ELBOW\")\n",
        "        wrist = landmarks.get(f\"{side}_WRIST\")\n",
        "        if shoulder and elbow and wrist:\n",
        "            ang = _angle_deg(np.array(shoulder), np.array(elbow), np.array(wrist))\n",
        "            if ang is not None:\n",
        "                angles.append(ang)\n",
        "    metrics[\"front_elbow_deg\"] = min(angles) if angles else None\n",
        "\n",
        "    # Spine lean\n",
        "    if \"MID_HIP\" in landmarks and \"MID_SHOULDER\" in landmarks:\n",
        "        metrics[\"spine_lean_deg\"] = _angle_vs_vertical(\n",
        "            np.array(landmarks[\"MID_HIP\"]),\n",
        "            np.array(landmarks[\"MID_SHOULDER\"])\n",
        "        )\n",
        "    else:\n",
        "        metrics[\"spine_lean_deg\"] = None\n",
        "\n",
        "    # Head over knee alignment\n",
        "    head = landmarks.get(\"NOSE\")\n",
        "    knee = landmarks.get(\"LEFT_KNEE\") or landmarks.get(\"RIGHT_KNEE\")\n",
        "    if head and knee:\n",
        "        dx = abs(head[0] - knee[0]) / frame_w\n",
        "        metrics[\"head_knee_dx_ratio\"] = dx\n",
        "    else:\n",
        "        metrics[\"head_knee_dx_ratio\"] = None\n",
        "\n",
        "    # Foot angle\n",
        "    foot = landmarks.get(\"LEFT_FOOT_INDEX\") or landmarks.get(\"RIGHT_FOOT_INDEX\")\n",
        "    ankle = landmarks.get(\"LEFT_ANKLE\") or landmarks.get(\"RIGHT_ANKLE\")\n",
        "    if foot and ankle:\n",
        "        metrics[\"foot_angle_deg\"] = _line_angle_vs_x_axis(np.array(ankle), np.array(foot))\n",
        "    else:\n",
        "        metrics[\"foot_angle_deg\"] = None\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "7x7qo2Yo0-qf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Draw overlays"
      ],
      "metadata": {
        "id": "78sSFQTM1RNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_overlays(frame, metrics, th: Thresholds):\n",
        "    y_offset = 50\n",
        "    def draw_cue(condition, label, value=None):\n",
        "        nonlocal y_offset\n",
        "        if condition:\n",
        "            overlay_png(frame, check_img, 10, y_offset, scale=0.1)\n",
        "            cv2.putText(frame, f\"{label}: {value}\", (60, y_offset+20),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "        else:\n",
        "            overlay_png(frame, cross_img, 10, y_offset, scale=0.1)\n",
        "            cv2.putText(frame, f\"{label}: {value}\", (60, y_offset+20),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "        y_offset += 50\n",
        "\n",
        "    fe = metrics.get(\"front_elbow_deg\")\n",
        "    sl = metrics.get(\"spine_lean_deg\")\n",
        "    hk = metrics.get(\"head_knee_dx_ratio\")\n",
        "    fa = metrics.get(\"foot_angle_deg\")\n",
        "\n",
        "    if fe is not None:\n",
        "        draw_cue(th.elbow_min <= fe <= th.elbow_max, \"Elbow\", f\"{fe:.1f}°\")\n",
        "    if sl is not None:\n",
        "        draw_cue(sl <= th.spine_lean_max, \"Spine Lean\", f\"{sl:.1f}°\")\n",
        "    if hk is not None:\n",
        "        draw_cue(hk <= th.head_knee_max_px_ratio, \"Head-Knee Align\", f\"{hk:.3f}\")\n",
        "    if fa is not None:\n",
        "        draw_cue(abs(fa - th.foot_angle_target) <= th.foot_angle_tol, \"Foot Angle\", f\"{fa:.1f}°\")\n",
        "\n",
        "# =========================\n",
        "# Video download\n",
        "# =========================\n",
        "def get_video_path(input_src, out_dir):\n",
        "    if input_src.startswith(\"http\"):\n",
        "        out_file = out_dir / \"input.mp4\"\n",
        "        ydl_opts = {\"outtmpl\": str(out_file), \"format\": \"mp4/bestaudio/best\"}\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([input_src])\n",
        "        return str(out_file)\n",
        "    return input_src"
      ],
      "metadata": {
        "id": "_-yC_BFk1ZJS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main analysis"
      ],
      "metadata": {
        "id": "UySAv6G61gdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_video():\n",
        "    stats = RunningStats()\n",
        "    src_path = get_video_path(INPUT_VIDEO, OUTPUT_DIR)\n",
        "    cap = cv2.VideoCapture(src_path)\n",
        "    out_path = OUTPUT_DIR / \"annotated_video.mp4\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Error: cannot read video\")\n",
        "        return\n",
        "    in_h, in_w = frame.shape[:2]\n",
        "    scale = TARGET_WIDTH / in_w\n",
        "    out_h = int(in_h * scale)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "    writer = cv2.VideoWriter(str(out_path), fourcc, TARGET_FPS, (TARGET_WIDTH, out_h))\n",
        "\n",
        "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "        while True:\n",
        "            ok, frame = cap.read()\n",
        "            if not ok:\n",
        "                break\n",
        "            frame = cv2.resize(frame, (TARGET_WIDTH, out_h))\n",
        "            results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            if results.pose_landmarks:\n",
        "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "                landmarks = landmarks_to_xy(TARGET_WIDTH, out_h, results.pose_landmarks)\n",
        "                m = compute_metrics(landmarks, TARGET_WIDTH)\n",
        "\n",
        "                # Store stats\n",
        "                if m[\"front_elbow_deg\"] is not None: stats.elbow_angles.append(m[\"front_elbow_deg\"])\n",
        "                if m[\"spine_lean_deg\"] is not None: stats.spine_leans.append(m[\"spine_lean_deg\"])\n",
        "                if m[\"head_knee_dx_ratio\"] is not None: stats.head_knee_dxs.append(m[\"head_knee_dx_ratio\"])\n",
        "                if m[\"foot_angle_deg\"] is not None: stats.foot_angles.append(m[\"foot_angle_deg\"])\n",
        "\n",
        "                draw_overlays(frame, m, Thresholds())\n",
        "\n",
        "            writer.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "\n",
        "    # Final evaluation\n",
        "    evaluation = {\n",
        "        \"Footwork\": score_and_feedback(stats.foot_angles, 25, 20),\n",
        "        \"Head Position\": score_and_feedback(stats.head_knee_dxs, 0, 0.06, inverse=True),\n",
        "        \"Swing Control\": score_and_feedback(stats.elbow_angles, 115, 35),\n",
        "        \"Balance\": score_and_feedback(stats.spine_leans, 0, 20, inverse=True),\n",
        "        \"Follow-through\": score_and_feedback(stats.elbow_angles, 115, 35)\n",
        "    }\n",
        "    with open(OUTPUT_DIR / \"evaluation.json\", \"w\") as f:\n",
        "        json.dump(evaluation, f, indent=2)\n",
        "\n",
        "    print(f\"Done! Video saved to {out_path}, evaluation saved to evaluation.json\")\n",
        "    return out_path\n"
      ],
      "metadata": {
        "id": "s-0UHx7x1lp-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple scoring function"
      ],
      "metadata": {
        "id": "qHY99vkl1wLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_and_feedback(values, target, tol, inverse=False):\n",
        "    if not values:\n",
        "        return {\"score\": 0, \"feedback\": \"No data available\"}\n",
        "    avg_val = sum(values) / len(values)\n",
        "    diff = abs(avg_val - target)\n",
        "    if inverse:\n",
        "        score = max(1, 10 - int((avg_val / tol) * 10))\n",
        "    else:\n",
        "        score = max(1, 10 - int((diff / tol) * 10))\n",
        "    feedback = \"Good form\" if score >= 8 else \"Needs improvement\"\n",
        "    return {\"score\": score, \"average\": avg_val, \"feedback\": feedback}"
      ],
      "metadata": {
        "id": "5-X0Lf4z1yGT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "tBvc_vRM15tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    analyze_video()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfDb-QYn1-RP",
        "outputId": "86fcc479-a9c8-433b-9e89-8b5a870ba938"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtube.com/shorts/vSX3IRxGnNY\n",
            "[youtube] vSX3IRxGnNY: Downloading webpage\n",
            "[youtube] vSX3IRxGnNY: Downloading tv client config\n",
            "[youtube] vSX3IRxGnNY: Downloading player 6b03aad7-main\n",
            "[youtube] vSX3IRxGnNY: Downloading tv player API JSON\n",
            "[youtube] vSX3IRxGnNY: Downloading ios player API JSON\n",
            "[youtube] vSX3IRxGnNY: Downloading m3u8 information\n",
            "[info] vSX3IRxGnNY: Downloading 1 format(s): 18\n",
            "[download] Destination: /content/output/input.mp4\n",
            "[download] 100% of  337.54KiB in 00:00:00 at 1.56MiB/s   \n",
            "Done! Video saved to /content/output/annotated_video.mp4, evaluation saved to evaluation.json\n"
          ]
        }
      ]
    }
  ]
}